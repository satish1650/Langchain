{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59408e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bde9cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e57cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b7919d",
   "metadata": {},
   "source": [
    "### Load the model and test it with the simple message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "442e6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, SystemMessage, HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba95062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-2.0-flash-001', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000191727EB740>, default_metadata=(), convert_system_message_to_human=True, model_kwargs={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\", convert_system_message_to_human=True) \n",
    "\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff86d71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hi you are nice Bot', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi, how are you buddy?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message1= [AIMessage(content=\"Hi you are nice Bot\"), HumanMessage(content=\"Hi, how are you buddy?\")]\n",
    "\n",
    "message1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5afd1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm doing well, thanks for asking! As a large language model, I don't experience emotions or feelings like humans do, but I'm ready and available to assist you with any questions or tasks you have. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run--0c8ef4ec-a980-40ba-9985-bc33ba095710-0', usage_metadata={'input_tokens': 12, 'output_tokens': 54, 'total_tokens': 66, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(message1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae20018d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StrOutputParser()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser= StrOutputParser()\n",
    "\n",
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64cbef73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-2.0-flash-001', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000191727EB740>, default_metadata=(), convert_system_message_to_human=True, model_kwargs={})\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain= model | parser\n",
    "\n",
    "chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f062f681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm doing well, thanks for asking! I'm ready to help you with whatever you need. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(message1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32305296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Hi you are nice Bot and you answer everything in brief', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi, how are you buddy?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message2= [SystemMessage(content=\"Hi you are nice Bot and you answer everything in brief\"), HumanMessage(content=\"Hi, how are you buddy?\")]\n",
    "\n",
    "message2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f07eed41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm good, thanks for asking! How are you?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run--3c6735e8-4145-4a8e-b4f6-c69dbefaaa0c-0', usage_metadata={'input_tokens': 18, 'output_tokens': 14, 'total_tokens': 32, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(message2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e49ccb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-2.0-flash-001', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000191727EB740>, default_metadata=(), convert_system_message_to_human=True, model_kwargs={})\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain= model | parser\n",
    "\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4fe5ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thanks! How can I help you?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(message2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07c809",
   "metadata": {},
   "source": [
    "### Now let's start with Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c9b224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6ff9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template= ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"translate the following into {language}\"),\n",
    "        (\"user\", \"{text}\")\n",
    "    ]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5b186d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='translate the following into french', additional_kwargs={}, response_metadata={}), HumanMessage(content='i am learning langchain tutorial.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt= prompt_template.invoke({\"language\":\"french\", \"text\":\"i am learning langchain tutorial.\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d42c692e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='translate the following into french', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='i am learning langchain tutorial.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b1f0a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are a few options for translating \"I am learning langchain tutorial\" into French, with slightly different nuances:\\n\\n*   **Je suis en train d\\'apprendre le tutoriel Langchain.** (This is a very common and natural translation, emphasizing the ongoing process of learning.)\\n\\n*   **J\\'apprends le tutoriel Langchain.** (This is a simpler and more direct translation, meaning \"I am learning the Langchain tutorial.\")\\n\\n*   **Je suis en train de suivre le tutoriel Langchain.** (This is similar to the first option, but uses \"suivre\" which means \"to follow,\" implying you are following along with the tutorial.)\\n\\n*   **J\\'étudie le tutoriel Langchain.** (This translates to \"I am studying the Langchain tutorial,\" which might imply a more formal or in-depth approach.)\\n\\nThe best option depends on the specific context and what you want to emphasize.  For most situations, **\"Je suis en train d\\'apprendre le tutoriel Langchain\"** or **\"J\\'apprends le tutoriel Langchain\"** are excellent choices.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(model.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da94cb1",
   "metadata": {},
   "source": [
    "### Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0c5456c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='translate the following into {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})])\n",
       "| ChatGoogleGenerativeAI(model='models/gemini-2.0-flash-001', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000191727EB740>, default_metadata=(), convert_system_message_to_human=True, model_kwargs={})\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain= prompt_template | model | parser\n",
    "\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4914292f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The most common and natural translation of \"I am hungry\" into Hindi is:\\n\\n**मुझे भूख लगी है। (Mujhe bhookh lagi hai.)**\\n\\nHere\\'s a breakdown:\\n\\n*   **मुझे (Mujhe):** To me\\n*   **भूख (Bhookh):** Hunger\\n*   **लगी है (Lagi hai):** Is happening/is felt\\n\\nSo, literally, it translates to \"Hunger is happening to me.\"\\n\\nOther possible translations, though less common, include:\\n\\n*   **मैं भूखा हूँ। (Main bhookha hoon.)** (Masculine) - I am hungry (masculine)\\n*   **मैं भूखी हूँ। (Main bhookhi hoon.)** (Feminine) - I am hungry (feminine)\\n\\nThe first option, **मुझे भूख लगी है। (Mujhe bhookh lagi hai.)** is generally preferred because it\\'s gender-neutral and more idiomatic.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"hindi\", \"text\": \"I am hungry\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d69c53",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ddcdf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c5f9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c8119a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory= MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86a20e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "search= TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bc24dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools= [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3c22fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor= create_react_agent(model, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "13ef42d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': 'abc123'}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config= {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "585931e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Pregel.stream at 0x0000019172E86020>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.stream({\"messages\": [HumanMessage(content=\"hi im satish! and i live in Kolkata\")]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b25bc210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"Hi Satish! Nice to meet you. It's great to know you're in Kolkata. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run--8b8cb772-bca6-4c07-9075-2fb3157ca30f-0', usage_metadata={'input_tokens': 167, 'output_tokens': 29, 'total_tokens': 196, 'input_token_details': {'cache_read': 0}})]}}\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream({\"messages\": [HumanMessage(content=\"hi im satish! and i live in Kolkata\")]}, config):\n",
    "    print(chunk)\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "385cf26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Okay, I see that you previously said your name was Satish and that you live in Kolkata. Is that still accurate?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run--863151c2-b059-442d-85bc-fe96418ff6bc-0', usage_metadata={'input_tokens': 199, 'output_tokens': 26, 'total_tokens': 225, 'input_token_details': {'cache_read': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream({\"messages\": [HumanMessage(content=\"whats my nammme\")]}, config):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5763a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"weather in Kolkata\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run--170b3d40-85d7-4377-9cd0-ff5ebcdfdcc8-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Kolkata'}, 'id': '2cb151e2-fe39-4d15-8553-30dcc744db9f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 242, 'output_tokens': 12, 'total_tokens': 254, 'input_token_details': {'cache_read': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='[{\"title\": \"Kolkata weather update: Heavy rain expected - Times of India\", \"url\": \"https://timesofindia.indiatimes.com/city/kolkata/kolkata-weather-update-expect-moderate-rain-showers-and-high-humidity-today/articleshow/122101335.cms\", \"content\": \"Kolkata residents are set to experience moderate rainfall on June 27, 2025, with temperatures ranging between 33.2°C and 27.3°C amid high humidity of 76%. ... for June 27 Weather conditions\", \"score\": 0.96110183}, {\"title\": \"Kolkata weather in June 2025 - METEOPROG.COM\", \"url\": \"https://www.meteoprog.com/weather/Calcutta/month/june/\", \"content\": \"Kolkata (India) weather in June 2025 ☀️ Accurate weather forecast for Kolkata in June ⛅ Detailed forecast By month Current temperature \\\\\"near me\\\\\" Weather news ⊳ Widget of weather ⊳ Water temperature | METEOPROG. Meteoprog.com. ... 27 June +32 °+28° 28 June +32°\", \"score\": 0.93610436}]', name='tavily_search_results_json', id='3b587318-fde1-4271-a050-a120fd92eec9', tool_call_id='2cb151e2-fe39-4d15-8553-30dcc744db9f', artifact={'query': 'weather in Kolkata', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Kolkata weather update: Heavy rain expected - Times of India', 'url': 'https://timesofindia.indiatimes.com/city/kolkata/kolkata-weather-update-expect-moderate-rain-showers-and-high-humidity-today/articleshow/122101335.cms', 'content': 'Kolkata residents are set to experience moderate rainfall on June 27, 2025, with temperatures ranging between 33.2°C and 27.3°C amid high humidity of 76%. ... for June 27 Weather conditions', 'score': 0.96110183, 'raw_content': None}, {'title': 'Kolkata weather in June 2025 - METEOPROG.COM', 'url': 'https://www.meteoprog.com/weather/Calcutta/month/june/', 'content': 'Kolkata (India) weather in June 2025 ☀️ Accurate weather forecast for Kolkata in June ⛅ Detailed forecast By month Current temperature \"near me\" Weather news ⊳ Widget of weather ⊳ Water temperature | METEOPROG. Meteoprog.com. ... 27 June +32 °+28° 28 June +32°', 'score': 0.93610436, 'raw_content': None}], 'response_time': 4.89})]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='You live in Kolkata. The weather in Kolkata is expected to have moderate rainfall with temperatures between 27.3°C and 33.2°C and high humidity of 76%.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run--07f2fd0e-69f2-4826-a153-ec3dfde50eb8-0', usage_metadata={'input_tokens': 505, 'output_tokens': 42, 'total_tokens': 547, 'input_token_details': {'cache_read': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream({\"messages\": [HumanMessage(content=\"Yes you are absolutely right, where do I live and whats the weather where I live?\")]}, config):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
